{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Car prices\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Répertorier l'ensemble des marques de véhicules\n",
    "2. Répertorier l'ensemble des modèles de véhicules\n",
    "3. Répertorier l'ensemble des prix des véhicules\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dossier « Dataframe » est existant\n",
      "Le dossier « Output » est existant\n",
      "Le dossier « Data » est existant\n",
      "\n",
      "c:\\Users\\Charles_tour\\Documents\\GitHub\\car_sales_forcast\\\n",
      "c:\\Users\\Charles_tour\\Documents\\GitHub\\car_sales_forcast\\Data\\\n",
      "c:\\Users\\Charles_tour\\Documents\\GitHub\\car_sales_forcast\\Dataframe\\\n",
      "c:\\Users\\Charles_tour\\Documents\\GitHub\\car_sales_forcast\\Output\\\n"
     ]
    }
   ],
   "source": [
    "# Create folders and getting path\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Loop to create folders\n",
    "folder_names = ['Dataframe', 'Output', 'Data']\n",
    "\n",
    "folders = {}\n",
    "for folder_name in folder_names:\n",
    "    folders[folder_name] = os.path.join(cwd, folder_name)\n",
    "\n",
    "    if not os.path.exists(os.path.join(cwd, folder_name)):\n",
    "        os.makedirs(os.path.join(cwd, folder_name))\n",
    "        print(f'Le dossier « {folder_name} » a été créé')\n",
    "\n",
    "    else:\n",
    "        print(f'Le dossier « {folder_name} » est existant')\n",
    "\n",
    "\n",
    "# Création des variables de path\n",
    "\n",
    "# Déterminer si os est win ou linux pour définir les path\n",
    "if os.name == 'nt':\n",
    "    slash = '\\\\'\n",
    "elif os.name == 'posix':\n",
    "    slash = '/'\n",
    "\n",
    "path_prog =     cwd + slash\n",
    "path_data =     folders['Data'] + slash\n",
    "path_df =       folders['Dataframe'] + slash\n",
    "path_output =   folders['Output'] + slash\n",
    "\n",
    "# Mettre \\\\ pour éviter les erreurs\n",
    "path_dict = [path_prog, path_data, path_df, path_output]\n",
    "for path in path_dict:\n",
    "    path = path.replace('\\\\','\\\\\\\\')\n",
    "\n",
    "\n",
    "# Détermination de l'année\n",
    "print()\n",
    "print(path_prog)\n",
    "print(path_data)\n",
    "print(path_df)\n",
    "print(path_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "from datetime import date\n",
    "import re\n",
    "\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "link_original        = 'https://www.guideautoweb.com'\n",
    "link_constructeur   = 'https://www.guideautoweb.com/constructeurs/'\n",
    "response_api = requests.get(link_constructeur, verify=False)\n",
    "print(response_api.status_code)     # 200 is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marque</th>\n",
       "      <th>link_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/alfa-romeo/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allard</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/allard/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       marque                                              link_model\n",
       "0       Acura       https://www.guideautoweb.com/constructeurs/acura/\n",
       "1  Alfa Romeo  https://www.guideautoweb.com/constructeurs/alfa-romeo/\n",
       "2      Allard      https://www.guideautoweb.com/constructeurs/allard/"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1ere page : Constructeur\n",
    "# Extraire toutes les marques et tous leurs liens \n",
    "\n",
    "# Get the data from api\n",
    "html_constructeur = response_api.text\n",
    "soup_constructeur = BeautifulSoup(html_constructeur, 'html.parser')\n",
    "\n",
    "# Extraire les marques de la page principale\n",
    "ul_element = soup_constructeur.find('ul', id='brands-index-list')\n",
    "\n",
    "data_marque = {\n",
    "    'marque' : [],\n",
    "    'link_model' : []\n",
    "}\n",
    "\n",
    "# Extract information from <a> elements within the <ul> element\n",
    "for a_element in ul_element.find_all('a'):\n",
    "    a_text = a_element.get_text().strip()\n",
    "    a_href = a_element.get('href')\n",
    "    link_model = link_original + a_href\n",
    "\n",
    "    data_marque['marque'].append(a_text)\n",
    "    data_marque['link_model'].append(link_model)\n",
    "\n",
    "df = pd.DataFrame(data_marque)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>link_model</th>\n",
       "      <th>production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura Integra</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/integra/2023/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura MDX</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2023/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acura RDX</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/rdx/2023/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acura TLX</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/tlx/2023/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acura CL</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/cl/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acura Concept</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/concept/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acura CSX</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/csx/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acura EL</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/el/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acura ILX</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/ilx/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acura NSX</td>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/nsx/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  \\\n",
       "0  Acura Integra   \n",
       "1      Acura MDX   \n",
       "2      Acura RDX   \n",
       "3      Acura TLX   \n",
       "4       Acura CL   \n",
       "5  Acura Concept   \n",
       "6      Acura CSX   \n",
       "7       Acura EL   \n",
       "8      Acura ILX   \n",
       "9      Acura NSX   \n",
       "\n",
       "                                                       link_model  production  \n",
       "0  https://www.guideautoweb.com/constructeurs/acura/integra/2023/        True  \n",
       "1      https://www.guideautoweb.com/constructeurs/acura/mdx/2023/        True  \n",
       "2      https://www.guideautoweb.com/constructeurs/acura/rdx/2023/        True  \n",
       "3      https://www.guideautoweb.com/constructeurs/acura/tlx/2023/        True  \n",
       "4            https://www.guideautoweb.com/constructeurs/acura/cl/       False  \n",
       "5       https://www.guideautoweb.com/constructeurs/acura/concept/       False  \n",
       "6           https://www.guideautoweb.com/constructeurs/acura/csx/       False  \n",
       "7            https://www.guideautoweb.com/constructeurs/acura/el/       False  \n",
       "8           https://www.guideautoweb.com/constructeurs/acura/ilx/       False  \n",
       "9           https://www.guideautoweb.com/constructeurs/acura/nsx/       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2e page : Modèle\n",
    "# Extraire tous les modèles et leurs liens\n",
    "\n",
    "# Loop pour Extraire modèle de la seconde page\n",
    "count = 0\n",
    "nombre_iteration = 2\n",
    "\n",
    "data_model = {\n",
    "    'model' : [],\n",
    "    'link_model' : [],\n",
    "    'production' : []\n",
    "    }\n",
    "\n",
    "for link in df['link_model']:\n",
    "    # if count >= nombre_iteration:\n",
    "    #     break \n",
    "\n",
    "    model_api = requests.get(link, verify=False)\n",
    "    # count += 1\n",
    "    html_model = model_api.text\n",
    "    soup_model = BeautifulSoup(html_model, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "    # Extract model en production\n",
    "    section_EnProduction = soup_model.find_all('div', class_='s')\n",
    "\n",
    "    extracted_text_list = []\n",
    "    extracted_ref_list = []\n",
    "\n",
    "    for section in section_EnProduction:\n",
    "        try:                                                        # Some model have no element, that cause an error\n",
    "            a_elements = section.find_all('a', class_='e-a e-t')\n",
    "\n",
    "            for a_element in a_elements:\n",
    "                extracted_text_list.append(a_element.get_text())\n",
    "                extracted_ref_list.append(a_element.get('href'))\n",
    "\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "    for text, ref in zip(extracted_text_list, extracted_ref_list):\n",
    "        data_model['model'].append(text)\n",
    "        data_model['link_model'].append(link_original + ref)\n",
    "        data_model['production'].append(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Extracting model non en production\n",
    "    section_production_autre = soup_model.find('ul', class_='eg eg-t1 eg-sz-s')\n",
    "    if section_production_autre:\n",
    "        for a_element in section_production_autre.find_all('a', class_='txt'):\n",
    "            try:\n",
    "                text = a_element.get_text()\n",
    "                data_model['model'].append(text)\n",
    "                data_model['link_model'].append(link_original + a_element.get('href'))\n",
    "                data_model['production'].append(False)\n",
    "                \n",
    "            except AttributeError:\n",
    "                continue\n",
    "\n",
    "    df_model = pd.DataFrame(data_model)\n",
    "\n",
    "df_model.to_excel(path_output + 'df_model.xlsx')\n",
    "\n",
    "df_model.head(10)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_model_an</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/integra/2023/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2023/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2022/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2020/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2019/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2013/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2012/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2011/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2010/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2009/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4347 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       link_model_an\n",
       "0     https://www.guideautoweb.com/constructeurs/acura/integra/2023/\n",
       "1         https://www.guideautoweb.com/constructeurs/acura/mdx/2023/\n",
       "2         https://www.guideautoweb.com/constructeurs/acura/mdx/2022/\n",
       "3         https://www.guideautoweb.com/constructeurs/acura/mdx/2020/\n",
       "4         https://www.guideautoweb.com/constructeurs/acura/mdx/2019/\n",
       "...                                                              ...\n",
       "4342     https://www.guideautoweb.com/constructeurs/volvo/xc70/2013/\n",
       "4343     https://www.guideautoweb.com/constructeurs/volvo/xc70/2012/\n",
       "4344     https://www.guideautoweb.com/constructeurs/volvo/xc70/2011/\n",
       "4345     https://www.guideautoweb.com/constructeurs/volvo/xc70/2010/\n",
       "4346     https://www.guideautoweb.com/constructeurs/volvo/xc70/2009/\n",
       "\n",
       "[4347 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraire le liens vers années et marque et modèle\n",
    "df_ModelAndYear = df_model\n",
    "\n",
    "data_df_ModelAndYear = {\n",
    "    'link_model_an' : []\n",
    "}\n",
    "\n",
    "for index, row in df_ModelAndYear.iterrows():\n",
    "    AnMod_api = requests.get(row['link_model'], verify=False)\n",
    "    soup_AnMod = BeautifulSoup(AnMod_api.text, 'html.parser')\n",
    "\n",
    "    annee_list = []\n",
    "\n",
    "    h1_section = soup_AnMod.find('h1', class_='st st-s3')\n",
    "    \n",
    "    for option in h1_section.find_all('option'):\n",
    "        data_df_ModelAndYear['link_model_an'].append(link_original + option.get('value'))     \n",
    "\n",
    "df_model2 = pd.DataFrame(data_df_ModelAndYear)\n",
    "\n",
    "df_model2\n",
    "# 8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_model_an</th>\n",
       "      <th>year</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/integra/2023/</td>\n",
       "      <td>2023</td>\n",
       "      <td>integra</td>\n",
       "      <td>acura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2023/</td>\n",
       "      <td>2023</td>\n",
       "      <td>mdx</td>\n",
       "      <td>acura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2022/</td>\n",
       "      <td>2022</td>\n",
       "      <td>mdx</td>\n",
       "      <td>acura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2020/</td>\n",
       "      <td>2020</td>\n",
       "      <td>mdx</td>\n",
       "      <td>acura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/acura/mdx/2019/</td>\n",
       "      <td>2019</td>\n",
       "      <td>mdx</td>\n",
       "      <td>acura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2013/</td>\n",
       "      <td>2013</td>\n",
       "      <td>xc70</td>\n",
       "      <td>volvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2012/</td>\n",
       "      <td>2012</td>\n",
       "      <td>xc70</td>\n",
       "      <td>volvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2011/</td>\n",
       "      <td>2011</td>\n",
       "      <td>xc70</td>\n",
       "      <td>volvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2010/</td>\n",
       "      <td>2010</td>\n",
       "      <td>xc70</td>\n",
       "      <td>volvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>https://www.guideautoweb.com/constructeurs/volvo/xc70/2009/</td>\n",
       "      <td>2009</td>\n",
       "      <td>xc70</td>\n",
       "      <td>volvo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4347 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       link_model_an  year  \\\n",
       "0     https://www.guideautoweb.com/constructeurs/acura/integra/2023/  2023   \n",
       "1         https://www.guideautoweb.com/constructeurs/acura/mdx/2023/  2023   \n",
       "2         https://www.guideautoweb.com/constructeurs/acura/mdx/2022/  2022   \n",
       "3         https://www.guideautoweb.com/constructeurs/acura/mdx/2020/  2020   \n",
       "4         https://www.guideautoweb.com/constructeurs/acura/mdx/2019/  2019   \n",
       "...                                                              ...   ...   \n",
       "4342     https://www.guideautoweb.com/constructeurs/volvo/xc70/2013/  2013   \n",
       "4343     https://www.guideautoweb.com/constructeurs/volvo/xc70/2012/  2012   \n",
       "4344     https://www.guideautoweb.com/constructeurs/volvo/xc70/2011/  2011   \n",
       "4345     https://www.guideautoweb.com/constructeurs/volvo/xc70/2010/  2010   \n",
       "4346     https://www.guideautoweb.com/constructeurs/volvo/xc70/2009/  2009   \n",
       "\n",
       "        model  brand  \n",
       "0     integra  acura  \n",
       "1         mdx  acura  \n",
       "2         mdx  acura  \n",
       "3         mdx  acura  \n",
       "4         mdx  acura  \n",
       "...       ...    ...  \n",
       "4342     xc70  volvo  \n",
       "4343     xc70  volvo  \n",
       "4344     xc70  volvo  \n",
       "4345     xc70  volvo  \n",
       "4346     xc70  volvo  \n",
       "\n",
       "[4347 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation d'une nouvelle df avec toutes les brand, model et year\n",
    "year_patern = r'\\b\\d{4}\\b'\n",
    "model_patern = r'/([^/]+)/\\d{4}/$'\n",
    "\n",
    "def extract_year(url):\n",
    "    match = re.search(year_patern, url)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_model(url):\n",
    "    match = re.search(model_patern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_brand(url):\n",
    "    parts = url.split('/')\n",
    "    if len(parts) >= 5:\n",
    "        return parts[4]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Apply the function to the 'link_model_an' column and create a new 'year' column\n",
    "df_model2['year'] = df_model2['link_model_an'].apply(extract_year)\n",
    "df_model2['model'] = df_model2['link_model_an'].apply(extract_model)\n",
    "df_model2['brand'] = df_model2['link_model_an'].apply(extract_brand)\n",
    "\n",
    "df_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Charles_tour\\Documents\\GitHub\\car_sales_forcast\\car_prices_scrapping.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Charles_tour/Documents/GitHub/car_sales_forcast/car_prices_scrapping.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Extraire le prix et la conso min et max\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Charles_tour/Documents/GitHub/car_sales_forcast/car_prices_scrapping.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df_model2\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Charles_tour/Documents/GitHub/car_sales_forcast/car_prices_scrapping.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     api \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(row[\u001b[39m'\u001b[39;49m\u001b[39mlink_model_an\u001b[39;49m\u001b[39m'\u001b[39;49m], verify\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Charles_tour/Documents/GitHub/car_sales_forcast/car_prices_scrapping.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     html \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mtext\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Charles_tour/Documents/GitHub/car_sales_forcast/car_prices_scrapping.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(html, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    468\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   1095\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1096\u001b[0m         (\n\u001b[0;32m   1097\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1102\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1103\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\urllib3\\connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    610\u001b[0m     sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    612\u001b[0m     server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m    613\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\urllib3\\connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[0;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[0;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extraire le prix et la conso min et max\n",
    "for index, row in df_model2.iterrows():\n",
    "    api = requests.get(row['link_model_an'], verify=False)\n",
    "    html = api.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Extraire les valeurs prix et consommation\n",
    "    value_element = soup.find_all(class_='value')\n",
    "\n",
    "    # Extraire prix min et prix max\n",
    "    price_text = value_element[0].get_text().strip()\n",
    "    prices = re.findall(r'\\d+(?:\\s?\\xa0?\\d+)?', price_text)\n",
    "    price_min = int(prices[0].replace('\\xa0', '')) if prices else None\n",
    "    price_max = int(prices[1].replace('\\xa0', '')) if len(prices) > 1 else None\n",
    "\n",
    "    # Extraire consom min et consom max et mettre none si non disponible\n",
    "    consom_text = value_element[1].get_text().strip().replace(',', '.')\n",
    "    consom = re.findall(r'\\d+(?:[.,]\\d+)?', consom_text)\n",
    "    consom_min = float(consom[0].replace('\\xa0', '')) if consom else None\n",
    "    consom_max = float(consom[1].replace('\\xa0', '')) if len(consom) > 1 else None\n",
    "\n",
    "    df_model2.at[index, 'prix_min'] = price_min\n",
    "    df_model2.at[index, 'prix_max'] = price_max\n",
    "    df_model2.at[index, 'cons_min'] = consom_min\n",
    "    df_model2.at[index, 'cons_max'] = consom_max\n",
    "\n",
    "df_model2\n",
    "# 19m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import concurrent.futures\n",
    "\n",
    "# Assuming you have already loaded your DataFrame df_model2\n",
    "\n",
    "def process_row(index, row):\n",
    "    api = requests.get(row['link_model_an'], verify=False)\n",
    "    html = api.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    value_element = soup.find_all(class_='value')\n",
    "\n",
    "    price_text = value_element[0].get_text().strip()\n",
    "    prices = re.findall(r'\\d+(?:\\s?\\xa0?\\d+)?', price_text)\n",
    "    price_min = int(prices[0].replace('\\xa0', '')) if prices else None\n",
    "    price_max = int(prices[1].replace('\\xa0', '')) if len(prices) > 1 else None\n",
    "\n",
    "    consom_text = value_element[1].get_text().strip().replace(',', '.')\n",
    "    consom = re.findall(r'\\d+(?:[.,]\\d+)?', consom_text)\n",
    "    consom_min = float(consom[0].replace('\\xa0', '')) if consom else None\n",
    "    consom_max = float(consom[1].replace('\\xa0', '')) if len(consom) > 1 else None\n",
    "\n",
    "    df_model2.at[index, 'prix_min'] = price_min\n",
    "    df_model2.at[index, 'prix_max'] = price_max\n",
    "    df_model2.at[index, 'cons_min'] = consom_min\n",
    "    df_model2.at[index, 'cons_max'] = consom_max\n",
    "\n",
    "# Create a ThreadPoolExecutor with a specified number of threads (adjust as needed)\n",
    "# You can experiment with the number of threads to find the optimal performance\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = [executor.submit(process_row, index, row) for index, row in df_model2.iterrows()]\n",
    "    \n",
    "    # Wait for all threads to finish\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# df_model2 is now updated with the processed values\n",
    "# 3m25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2.to_excel(path_output + 'df_model2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Optimisation \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    try:\n",
    "        response = requests.get(url, verify=False)\n",
    "        return BeautifulSoup(response.text, 'html')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Error fetching data from {url}: {e}')\n",
    "        return None\n",
    "    \n",
    "\n",
    "url_test = 'https://www.guideautoweb.com/constructeurs/acura/mdx/2018/'\n",
    "\n",
    "def extract_numeric_value(text):\n",
    "    text = text[0].get_text().strip()\n",
    "\n",
    "\n",
    "test = get_soup(url_test)\n",
    "test2 = find_value(test)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.guideautoweb.com/constructeurs/acura/mdx/2023/'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['link_year'][1][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
